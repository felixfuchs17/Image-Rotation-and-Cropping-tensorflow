{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting raw Tiny ImageNet dataset into TFRecords for object localization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Converts Tiny ImageNet data to TFRecords file format.\n",
    "\n",
    "* Reference: TensowFlow example code for converting ImageNet data to TFRecords file format\n",
    "    - Link: https://github.com/tensorflow/models/blob/master/research/inception/inception/data/build_imagenet_data.py\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "from scipy.ndimage import imread\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# To choose which GPU to use\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "VALIDATION_RATIO = 0.3\n",
    "\n",
    "# Directories\n",
    "TINY_IMAGENET_DIRECTORY = \"./dataset/tiny-imagenet-200\"\n",
    "TRAIN_DIRECTORY = TINY_IMAGENET_DIRECTORY + \"/train\"\n",
    "VALIDATION_DIRECTORTY = TINY_IMAGENET_DIRECTORY + \"/val\"\n",
    "WNIDS_DIRECTORY = TINY_IMAGENET_DIRECTORY + \"/wnids.txt\"\n",
    "WORDS_DIRECTORY = TINY_IMAGENET_DIRECTORY + \"/words.txt\"\n",
    "\n",
    "TEST_IMAGE_DIRECTORY = VALIDATION_DIRECTORTY + \"/images\"\n",
    "TEST_ANNOTATION = VALIDATION_DIRECTORTY + \"/val_annotations.txt\"\n",
    "\n",
    "TFRECORD_DIRECTORY = \"./dataset/tfrecords/\"\n",
    "PICKLE_DIR = \"./dataset/tfrecords/tiny_imagenet.pickle\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Util functions for converting raw dataset into tfrecord type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _onehot_encoder(label_list):\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = label_list.reshape(len(label_list), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    \n",
    "    return onehot_encoded\n",
    "\n",
    "def _process_image_files(tfrecord_dir, X, Y, Y_one_hot, Loc, num_label, shard_size=1000, prefix=''):\n",
    "    \"\"\"Processes and saves list of images as TFRecord.\n",
    "\n",
    "    Args:\n",
    "        - \n",
    "    Returns:\n",
    "        no return\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    try: os.makedirs(tfrecord_dir)\n",
    "    except: pass \n",
    "    \n",
    "    num_shards = len(X) // shard_size\n",
    "    num_shards += 0 if len(X) % shard_size == 0 else 1\n",
    "\n",
    "    for idx in range(num_shards):\n",
    "        X_shard = X[idx * shard_size: (idx + 1) * shard_size]        \n",
    "        Y_shard = Y[idx * shard_size: (idx + 1) * shard_size]\n",
    "        Y_shard_one_hot = Y_one_hot[idx * shard_size: (idx + 1) * shard_size]\n",
    "        Loc_shard = Loc[idx * shard_size: (idx + 1) * shard_size]\n",
    "        \n",
    "        output_filename = '%s-%.5d-of-%.5d.tfrecords' % (prefix, idx, num_shards)\n",
    "        output_file = os.path.join(tfrecord_dir, output_filename)\n",
    "        writer = tf.python_io.TFRecordWriter(output_file)\n",
    "        for i in range(len(X_shard)):\n",
    "\n",
    "            label = int(Y_shard[i])            \n",
    "            img_raw = X_shard[i].tostring()\n",
    "            location_raw = Loc_shard[i].tostring()\n",
    "            label_one_hot_raw = Y_shard_one_hot[i].tostring()\n",
    "            (height, width, channels) = X_shard[i].shape\n",
    "\n",
    "            example = _convert_to_example(height=height, width=width, channels=channels, label=label,\n",
    "                                          label_one_hot_raw=label_one_hot_raw, img_raw=img_raw, location_raw=location_raw)\n",
    "            writer.write(example.SerializeToString())\n",
    "\n",
    "def _convert_to_example(height, width, channels, label, label_one_hot_raw, img_raw, location_raw):\n",
    "    \"\"\"Build an Example proto for an example.\n",
    "\n",
    "    Args:\n",
    "        -\n",
    "    Returns:\n",
    "        Example proto\n",
    "\n",
    "    \"\"\"\n",
    "    colorspace = 'RGB'\n",
    "    channels = 3\n",
    "    image_format = 'JPEG'\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'height': _int64_feature(height),\n",
    "        'width': _int64_feature(width),\n",
    "        'channel': _int64_feature(channels),\n",
    "        'label': _int64_feature(label),\n",
    "        'label_depth': _int64_feature(label),\n",
    "\n",
    "        'label_one_hot_raw': _bytes_feature(label_one_hot_raw),\n",
    "        'image_raw': _bytes_feature(img_raw),\n",
    "        'location_raw': _bytes_feature(location_raw)}))\n",
    "    return example\n",
    "\n",
    "def _read_train_validation_data(train_directory, train_id_list, num_class):\n",
    "    element_list = ['X', 'Y', 'Loc']\n",
    "    train_origin = {'X':[], 'Y': [], 'Loc': []}\n",
    "    train = {'X':[], 'Y': [], 'O': [], 'Loc': []}\n",
    "    valid = {'X':[], 'Y': [], 'O': [], 'Loc': []}\n",
    "    # Read train_origin data and seperate it into two pieces: train and validation\n",
    "    train_dir_list = [os.path.join(train_directory, dir_) for dir_ in os.listdir(train_directory)]\n",
    "\n",
    "    # Read train, valid\n",
    "    for class_ in train_dir_list:    \n",
    "        bbox_dir = class_ + \"/\" + os.path.basename(class_) + \"_boxes.txt\"\n",
    "        image_dir = class_ + \"/images\"\n",
    "        image_dir_list = [os.path.join(image_dir, dir_) for dir_ in os.listdir(image_dir)]\n",
    "\n",
    "        with open(bbox_dir, \"r\") as bbox_f:\n",
    "            bbox_list = bbox_f.readlines()\n",
    "\n",
    "        image_to_bbox = {}\n",
    "        for line in bbox_list:\n",
    "            (image_file, x_pos, y_pos, w_pos, h_pos) = [w if i == 0 else int(w) for i, w in enumerate(line.split('\\t'))]\n",
    "            image_to_bbox[image_file] = [x_pos, y_pos, w_pos, h_pos]\n",
    "\n",
    "        for image_dir in image_dir_list:\n",
    "            train_origin['X'].append(imread(image_dir, mode='RGB'))\n",
    "            train_origin['Y'].append(train_id_list.index(os.path.basename(class_)))\n",
    "            train_origin['Loc'].append(image_to_bbox[os.path.basename(image_dir)])\n",
    "        \n",
    "    train_origin_list = [np.stack(train_origin[e]) for e in element_list]\n",
    "    num_train_data = len(train_origin_list[0])\n",
    "    rand = np.random.permutation(range(num_train_data))\n",
    "    for idx in range(len(train_origin_list)):\n",
    "        train_origin_list[idx] = train_origin_list[idx][rand]\n",
    "        \n",
    "    validation_ratio = VALIDATION_RATIO\n",
    "    train_idx = round(num_train_data*(1-validation_ratio))\n",
    "    train_list = []\n",
    "    valid_list = []\n",
    "    for part in train_origin_list:\n",
    "        train_list.append(part[:train_idx])\n",
    "    for part in train_origin_list:\n",
    "        valid_list.append(part[train_idx:])        \n",
    "    for i, e in enumerate(element_list):\n",
    "        train[e] = train_list[i]\n",
    "        valid[e] = valid_list[i] \n",
    "    \n",
    "    train['O'] = _onehot_encoder(train['Y'])\n",
    "    valid['O'] = _onehot_encoder(valid['Y'])\n",
    "        \n",
    "    return train, valid\n",
    "\n",
    "def _read_test_data(test_image_directory, train_id_list, num_class):\n",
    "    \n",
    "    element_list = ['X', 'Y', 'Loc']\n",
    "    test = {'X':[], 'Y': [], 'O': [], 'Loc': []}\n",
    "    \n",
    "    image_dir_list = [os.path.join(test_image_directory, dir_) for dir_ in os.listdir(test_image_directory)]\n",
    "    with open(TEST_ANNOTATION, \"r\") as val_f:\n",
    "        val_list = val_f.readlines()\n",
    "\n",
    "    image_to_bbox = {}\n",
    "    image_to_wnid = {}\n",
    "    for line in val_list:\n",
    "        (image_file, wnid, x_pos, y_pos, w_pos, h_pos) = [w if i == 0 or i == 1 else int(w) for i, w in enumerate(line.split('\\t'))]\n",
    "        image_to_bbox[image_file] = [x_pos, y_pos, w_pos, h_pos]\n",
    "        image_to_wnid[image_file] = wnid\n",
    "\n",
    "    for image_dir in image_dir_list:\n",
    "        test['X'].append(imread(image_dir, mode='RGB'))\n",
    "        test['Y'].append(train_id_list.index(image_to_wnid[os.path.basename(image_dir)]))\n",
    "        test['Loc'].append(image_to_bbox[os.path.basename(image_dir)])\n",
    "        \n",
    "    for e in element_list:\n",
    "        test[e] = np.stack(test[e])\n",
    "\n",
    "    test['O'] = _onehot_encoder(test['Y'])\n",
    "        \n",
    "    return test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the raw Tiny ImageNet dataset into TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries\n",
    "label_to_word = {}\n",
    "train = {}\n",
    "valid = {}\n",
    "test = {}\n",
    "data_dict = {}\n",
    "\n",
    "# Dictionary for tiny imagenet\n",
    "train_id_list = os.listdir(TRAIN_DIRECTORY) # len is 200\n",
    "num_class = len(train_id_list)\n",
    "with open(WORDS_DIRECTORY, \"r\") as words_f:\n",
    "    line_lists = words_f.readlines()\n",
    "words_f.close()\n",
    "\n",
    "for l in line_lists:    \n",
    "    wnid, word = l.split('\\t')    \n",
    "    if wnid in train_id_list:\n",
    "        label = train_id_list.index(wnid)\n",
    "        word = str(label) + \": \" + word\n",
    "        label_to_word[label] = word \n",
    "data_dict['label_to_word']=label_to_word\n",
    "\n",
    "train, valid = _read_train_validation_data(TRAIN_DIRECTORY, train_id_list, num_class)\n",
    "test = _read_test_data(TEST_IMAGE_DIRECTORY, train_id_list, num_class)\n",
    "\n",
    "for data_type in ['train', 'valid', 'test']:   \n",
    "    for e in ['X', 'Y', 'O', 'Loc']:\n",
    "        data_dict[data_type + '_' + e] = eval(data_type + '[\\'' + e + '\\']')\n",
    "\n",
    "    _process_image_files(TFRECORD_DIRECTORY + data_type,\n",
    "                   X=data_dict[data_type + '_' + 'X'],\n",
    "                   Y=data_dict[data_type + '_' + 'Y'],\n",
    "                   Y_one_hot=data_dict[data_type + '_' + 'O'],\n",
    "                   Loc=data_dict[data_type + '_' + 'Loc'],\n",
    "                   num_label=200,\n",
    "                   shard_size=2000,\n",
    "                   prefix=data_type)\n",
    "    \n",
    "data_dict['mean_RGB'] = train['X'].mean()\n",
    "\n",
    "try: os.makedirs(os.path.dirname(pickle_save_path))\n",
    "except: pass\n",
    "with open(PICKLE_DIR, \"wb\") as pickle_f:\n",
    "    pickle.dump(data_dict, pickle_f)\n",
    "pickle_f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
